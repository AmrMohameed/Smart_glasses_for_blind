{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Ali Metwally', 'top': 236, 'right': 1059, 'bottom': 315, 'left': 980}, {'name': 'Amr Eldeeb', 'top': 204, 'right': 795, 'bottom': 283, 'left': 716}, {'name': 'Mostafa Elnakib', 'top': 737, 'right': 1836, 'bottom': 851, 'left': 1722}, {'name': 'Mostafa Raafat', 'top': 806, 'right': 1156, 'bottom': 920, 'left': 1042}, {'name': 'Amgad Diiab', 'top': 799, 'right': 1463, 'bottom': 894, 'left': 1368}]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import face_recognition\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "# Load the jpg file into a numpy array\n",
    "#image = face_recognition.load_image_file(\"35686948_2010940409222504_8292923842406383616_n.jpg\")\n",
    "unkown_image = face_recognition.load_image_file(\"48357921_525266544655016_5182188839342440448_n.jpg\")\n",
    "annotations = pd.read_csv(\"Kown_Person/data_annotation.csv\")\n",
    "# Find all the faces in the image using a pre-trained convolutional neural network.\n",
    "# This method is more accurate than the default HOG model, but it's slower\n",
    "# unless you have an nvidia GPU and dlib compiled with CUDA extensions. But if you do,\n",
    "# this will use GPU acceleration and perform well.\n",
    "# See also: find_faces_in_picture.py\n",
    "#face_locations = face_recognition.face_locations(image, number_of_times_to_upsample=0, model=\"cnn\")\n",
    "unkown_face_locations = face_recognition.face_locations(unkown_image, number_of_times_to_upsample=0, model=\"cnn\")\n",
    "lis_dic =[]\n",
    "# print(\"I found {} face(s) in this photograph.\".format(len(face_locations)))\n",
    "# image_encoding = face_recognition.face_encodings(image,face_locations)[0]\n",
    "unkown_images_encoding = face_recognition.face_encodings(unkown_image,unkown_face_locations)\n",
    "for un_im,un_face_loc in zip(unkown_images_encoding,unkown_face_locations):\n",
    "    for index,row in annotations.iterrows():\n",
    "        face_locations = [row[\"top\"],row[\"right\"],row[\"bottom\"],row[\"left\"]]\n",
    "        name = row[\"Name\"]\n",
    "        path_image = row[\"path_image\"]\n",
    "        image = face_recognition.load_image_file(\"Kown_Person/\"+path_image)\n",
    "        image_encoding = face_recognition.face_encodings(image,[face_locations])[0]\n",
    "        result = face_recognition.compare_faces([image_encoding], un_im,tolerance=0.5)[0]\n",
    "#         print(result,name)\n",
    "        if result:\n",
    "            top, right, bottom, left = un_face_loc\n",
    "#             face_image = unkown_image[top:bottom, left:right]\n",
    "#             pil_image = Image.fromarray(face_image)\n",
    "#             display(pil_image)\n",
    "            dic_loc = {\"name\":name,\"top\":top,\"right\":right,\"bottom\":bottom,\"left\":left}\n",
    "            lis_dic.append(dic_loc)\n",
    "    # Print the location of each face in this image\n",
    "#     top, right, bottom, left = face_location\n",
    "#     print(\"A face is located at pixel location Top: {}, Left: {}, Bottom: {}, Right: {}\".format(top, left, bottom, right))\n",
    "\n",
    "    # You can access the actual face itself like this:\n",
    "#     face_image = image[top:bottom, left:right]\n",
    "#     pil_image = Image.fromarray(face_image)\n",
    "#     display(pil_image)\n",
    "print(lis_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
